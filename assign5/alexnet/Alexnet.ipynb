{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alexnet.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWgVQIQwQ_70"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHU2eoXbRGh7"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwSXf6zGRJgk"
      },
      "source": [
        "CLASS_NAMES= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKjsJY1sRNKY"
      },
      "source": [
        "# validation_images, validation_labels = train_images[:5000], train_labels[:5000]\n",
        "train_images, train_labels = train_images[35000:], train_labels[35000:]\n",
        "\n",
        "test_images, test_labels = test_images[7000:], test_labels[7000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_WwfWbBRRXd"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "# train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "# print(\"Training data size:\", train_ds_size)\n",
        "# validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoTtf7EJVtGo"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "# # print('x_train shape:', x_train.shape)\n",
        "# # print('X shape: ', x_test.shape)\n",
        "# # print('Y shape: ', x_test.shape)\n",
        "\n",
        "# second_size = 25000/50000\n",
        "\n",
        "# X1, X2 = train_test_split(train_ds, test_size=second_size)\n",
        "# Xt1, Xt2 = train_test_split(test_ds, test_size=second_size)\n",
        "\n",
        "# train_ds = X2\n",
        "# test_ds = Xt2\n",
        "\n",
        "# print('X_train shape: ', x_train.shape)\n",
        "# print('X_test shape: ', x_test.shape)\n",
        "# print('Y_train shape: ', y_train.shape)\n",
        "# print('Y_test shape: ', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_ATJEYtRU_U"
      },
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "for i, (image, label) in enumerate(train_ds.take(5)):\n",
        "    ax = plt.subplot(5,5,i+1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(CLASS_NAMES[label.numpy()[0]])\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8M5VEIURZIO"
      },
      "source": [
        "def process_images(image, label):\n",
        "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
        "    image = tf.image.per_image_standardization(image)\n",
        "    # Resize images from 32x32 to 277x277\n",
        "    image = tf.image.resize(image, (227,227))\n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFhyVRbtRjR2"
      },
      "source": [
        "train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "test_ds_size = tf.data.experimental.cardinality(test_ds).numpy()\n",
        "# validation_ds_size = tf.data.experimental.cardinality(validation_ds).numpy()\n",
        "print(\"Training data size:\", train_ds_size)\n",
        "print(\"Test data size:\", test_ds_size)\n",
        "# print(\"Validation data size:\", validation_ds_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SijYnt-LRliD"
      },
      "source": [
        "train_ds = (train_ds\n",
        "                  .map(process_images)\n",
        "                  .shuffle(buffer_size=train_ds_size)\n",
        "                  .batch(batch_size=32, drop_remainder=True))\n",
        "test_ds = (test_ds\n",
        "                  .map(process_images)\n",
        "                  .shuffle(buffer_size=train_ds_size)\n",
        "                  .batch(batch_size=32, drop_remainder=True))\n",
        "# validation_ds = (validation_ds\n",
        "#                   .map(process_images)\n",
        "#                   .shuffle(buffer_size=train_ds_size)\n",
        "#                   .batch(batch_size=32, drop_remainder=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eah7WnhRqtj"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    # keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    # keras.layers.BatchNormalization(),\n",
        "    # keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    # keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    # keras.layers.BatchNormalization(),\n",
        "    # keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    # keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=96, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(4096, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    # keras.layers.Dense(4096, activation='relu'),\n",
        "    # keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n90JYthCSCwV"
      },
      "source": [
        "root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
        "def get_run_logdir():\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir, run_id)\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXRMEcwFSH8L"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uf49Fw4SR4N"
      },
      "source": [
        "model.fit(train_ds,\n",
        "          epochs=5,\n",
        "          # validation_data=validation_ds,\n",
        "          # validation_freq=1,\n",
        "          callbacks=[tensorboard_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AdRq76ISa72"
      },
      "source": [
        "model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSxeokpb6XSZ"
      },
      "source": [
        "x = 5\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}