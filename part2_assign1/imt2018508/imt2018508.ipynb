{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-from-scratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWt8sLTRy1YK"
      },
      "source": [
        "**Import Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6A4lMBPyreZ"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf3U8NFHy7yU"
      },
      "source": [
        "**Objective : Design RNN for predicting sequence of characters from training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ociUAfFIyufu",
        "outputId": "f20cdcb2-f904-4711-8bdd-59f10cde75f7"
      },
      "source": [
        "class DataReader:\n",
        "  def __init__(self):\n",
        "    self.data = \"RNN from scratch\"\n",
        "    chars = list(set(self.data))\n",
        "    chars.append(\" \")\n",
        "    self.char_to_ix = {ch:i for (i,ch) in enumerate(chars)}\n",
        "    self.ix_to_char = {i:ch for (i,ch) in enumerate(chars)}\n",
        "    self.seq_length = len(self.data)\n",
        "    self.vocab_size = len(chars)\n",
        "    print(self.seq_length)\n",
        "    print(self.char_to_ix)\n",
        "    print(chars)\n",
        "\n",
        "\n",
        "  def get_inputs_targets(self, data):\n",
        "   inputs_str = data\n",
        "   target_str = data[1:] \n",
        "   target_str = target_str + \" \"  \n",
        "   inputs = [self.char_to_ix[ch] for ch in inputs_str] \n",
        "   targets = [self.char_to_ix[ch] for ch in target_str]\n",
        "   return inputs, targets\n",
        "\n",
        "datareader = DataReader()\n",
        "datareader.get_inputs_targets(datareader.data)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "{'r': 0, ' ': 12, 'N': 2, 'm': 3, 's': 4, 'R': 5, 'a': 6, 'h': 7, 'o': 8, 'c': 9, 'f': 10, 't': 11}\n",
            "['r', ' ', 'N', 'm', 's', 'R', 'a', 'h', 'o', 'c', 'f', 't', ' ']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([5, 2, 2, 12, 10, 0, 8, 3, 12, 4, 9, 0, 6, 11, 9, 7],\n",
              " [2, 2, 12, 10, 0, 8, 3, 12, 4, 9, 0, 6, 11, 9, 7, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm-HiCfszTp-"
      },
      "source": [
        "**RNN Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8XxzRrHzQKK"
      },
      "source": [
        "\n",
        "class RNN:\n",
        "  def __init__(self, hidden_size, vocab_size,seq_length,learning_rate):\n",
        "    self.hidden_size = hidden_size\n",
        "    self.vocab_size = vocab_size\n",
        "    self.seq_length = seq_length\n",
        "    self.learning_rate = learning_rate\n",
        "    # Model_Parameters\n",
        "    self.W_xh = np.random.uniform(-np.sqrt(1./vocab_size),np.sqrt(1./vocab_size), size=(hidden_size,vocab_size))\n",
        "    self.W_hh = np.random.uniform(-np.sqrt(1./hidden_size),np.sqrt(1./hidden_size), size=(hidden_size,hidden_size))\n",
        "    self.W_yh = np.random.uniform(-np.sqrt(1./hidden_size),np.sqrt(1./hidden_size), size=(vocab_size,hidden_size))\n",
        "    self.W_by = np.random.uniform(size=(vocab_size,1))\n",
        "    self.W_bh = np.random.uniform(size=(hidden_size,1))\n",
        "    # memory variables\n",
        "    self.mW_xh = np.zeros_like(self.W_xh)\n",
        "    self.mW_hh = np.zeros_like(self.W_hh)\n",
        "    self.mW_yh = np.zeros_like(self.W_yh)\n",
        "    self.mW_by = np.zeros_like(self.W_by)\n",
        "    self.mW_bh = np.zeros_like(self.W_bh)\n",
        "\n",
        "  \n",
        "  def softmax(self, x):\n",
        "    p = np.exp(x-np.max(x))\n",
        "    return p / np.sum(p)\n",
        "\n",
        "\n",
        "  def forward(self, inputs,hprev):\n",
        "    xs, hs, os, ycap = {},{},{},{}\n",
        "    hs[-1] = np.copy(hprev)\n",
        "    for t in range(len(inputs)):\n",
        "      xs[t] = np.zeros((self.vocab_size, 1))\n",
        "      xs[t][inputs[t]] = 1 # one-hot encoding\n",
        "      hs[t] = np.tanh(np.dot(self.W_hh,hs[t-1]) + np.dot(self.W_xh,xs[t]) + self.W_bh) \n",
        "      os[t] = np.dot(self.W_yh,hs[t]) + self.W_by\n",
        "      ycap[t] = self.softmax(os[t])\n",
        "      #print(xs[t].shape,hs[t].shape,os[t].shape,ycap[t].shape)\n",
        "    return xs, hs, ycap\n",
        "\n",
        "  def loss(self, ycap, targets):\n",
        "    return sum(-np.log(ycap[t][targets[t]]) for t in range(self.seq_length))\n",
        "\n",
        "  def backward(self, xs, hs, ycap,targets):\n",
        "    dW_xh = np.zeros_like(self.W_xh)\n",
        "    dW_hh = np.zeros_like(self.W_hh)\n",
        "    dW_yh = np.zeros_like(self.W_yh)\n",
        "    dW_by = np.zeros_like(self.W_by)\n",
        "    dW_bh = np.zeros_like(self.W_bh)\n",
        "    dhnext = np.zeros_like(hs[0])\n",
        "\n",
        "    for t in reversed(range(self.seq_length)):\n",
        "      d_yy_cap = np.copy(ycap[t])\n",
        "      d_yy_cap[targets[t]]-= 1\n",
        "      dW_yh += np.dot(d_yy_cap,hs[t].T)\n",
        "      dW_by += (d_yy_cap)\n",
        "      dL_dh = np.dot(self.W_yh.T,d_yy_cap) + dhnext\n",
        "      dL_dh_dtanh = (1 -hs[t]*hs[t])*dL_dh\n",
        "\n",
        "      dW_hh+= np.dot(dL_dh_dtanh, hs[t-1].T)\n",
        "      dW_xh+= np.dot(dL_dh_dtanh, xs[t].T)\n",
        "      dW_bh+= np.dot(dL_dh_dtanh, 1)\n",
        "\n",
        "      dhnext = np.dot(self.W_hh.T,dL_dh_dtanh)\n",
        "\n",
        "    return dW_xh, dW_hh, dW_yh, dW_by, dW_bh\n",
        "\n",
        "  def update_model(self, dW_xh, dW_hh, dW_yh,dW_by, dW_bh):\n",
        "    for param, dparam in zip([self.W_xh, self.W_hh, self.W_yh, self.W_by, self.W_bh],[dW_xh, dW_hh, dW_yh, dW_by, dW_bh]):\n",
        "      param+= -self.learning_rate*dparam\n",
        "\n",
        "  def adagrad_update_model(self, dW_xh, dW_hh, dW_yh,dW_by, dW_bh):\n",
        "    episilon = 1e-8\n",
        "    for param, dparam, temp in zip([self.W_xh, self.W_hh, self.W_yh, self.W_by, self.W_bh],[dW_xh, dW_hh, dW_yh, dW_by, dW_bh], \n",
        "                             [self.mW_xh, self.mW_hh, self.mW_yh, self.mW_by, self.mW_bh]):\n",
        "      temp = dparam*dparam\n",
        "      param += -(self.learning_rate/np.sqrt(temp+episilon))*dparam\n",
        "\n",
        "  def predict(self, data_reader, start_char, predict_len):\n",
        "    x = np.zeros((self.vocab_size,1))\n",
        "    ix = datareader.char_to_ix[start_char]\n",
        "    x[ix] = 1\n",
        "    indexes=[ix]\n",
        "    hs = np.zeros((self.hidden_size, 1))\n",
        "    for t in range(predict_len):\n",
        "      hs = np.tanh(np.dot(self.W_hh,hs) + np.dot(self.W_xh,x) + self.W_bh)\n",
        "      os = np.dot(self.W_yh,hs) + self.W_by\n",
        "      ycap = self.softmax(os)\n",
        "      ix = np.random.choice(range(self.vocab_size), p = ycap.ravel()) \n",
        "      x = np.zeros((self.vocab_size, 1))\n",
        "      x[ix]= 1\n",
        "      indexes.append(ix)\n",
        "    \n",
        "    txt = ''.join(data_reader.ix_to_char[i] for i in indexes)\n",
        "    print(txt)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "def train(hidden_layer, update_function):\n",
        "  datareader = DataReader()\n",
        "  inputs, targets = datareader.get_inputs_targets(datareader.data)\n",
        "  hidden_size = hidden_layer\n",
        "  rnn = RNN(hidden_size,datareader.vocab_size,len(inputs), 1e-03)\n",
        "  loss = 100\n",
        "  iter = 0\n",
        "  while(iter < 10000):\n",
        "    hprev= np.zeros((hidden_size, 1))\n",
        "    xs, hs , ycap = rnn.forward(inputs,hprev)\n",
        "    loss = rnn.loss(ycap, targets) \n",
        "    dW_xh, dW_hh, dW_yh, dW_by, dW_bh =  rnn.backward(xs, hs , ycap,targets)\n",
        "    if(update_function == \"Adagrad\"):\n",
        "      rnn.adagrad_update_model(dW_xh, dW_hh, dW_yh, dW_by, dW_bh)\n",
        "    else:\n",
        "      rnn.update_model(dW_xh, dW_hh, dW_yh, dW_by, dW_bh)\n",
        "    if not iter%1000:\n",
        "      print(\"iter num\", iter, loss)\n",
        "      print(rnn.predict(datareader,'R', rnn.seq_length))\n",
        "    iter+=1\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgoqlQIc6VRv"
      },
      "source": [
        "**TASK 1** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-JLvdtJ6xq9"
      },
      "source": [
        "adding bias variables to RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2cVVMfZeCjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6537d1-aa47-4014-c47f-aa26c76b324a"
      },
      "source": [
        "train(10, \"SGD\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "{'r': 0, ' ': 12, 'N': 2, 'm': 3, 's': 4, 'R': 5, 'a': 6, 'h': 7, 'o': 8, 'c': 9, 'f': 10, 't': 11}\n",
            "['r', ' ', 'N', 'm', 's', 'R', 'a', 'h', 'o', 'c', 'f', 't', ' ']\n",
            "iter num 0 [45.88606591]\n",
            "RmchRootaRcf sNom\n",
            "None\n",
            "iter num 1000 [18.95104944]\n",
            "RNNcr a scmtofrfr\n",
            "None\n",
            "iter num 2000 [5.31834374]\n",
            "RoN srfm fooma fr\n",
            "None\n",
            "iter num 3000 [2.31751402]\n",
            "R N from fcratcr \n",
            "None\n",
            "iter num 4000 [1.34732055]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 5000 [0.92062298]\n",
            "RNscrct tch N fro\n",
            "None\n",
            "iter num 6000 [0.69020964]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 7000 [0.54856352]\n",
            "RNN from scratcr \n",
            "None\n",
            "iter num 8000 [0.45359706]\n",
            "RNN frhm scratch \n",
            "None\n",
            "iter num 9000 [0.38587279]\n",
            "RNN from scratch \n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttDY9YGC6zq7"
      },
      "source": [
        "**TASK 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR5cbIT-Yf_X"
      },
      "source": [
        "**Using Adagrad gradient descent optimization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfIj9t7rejsB",
        "outputId": "cfe0c459-8317-44c0-fb7f-4292ecf4b270"
      },
      "source": [
        "train(10, \"Adagrad\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "{'r': 0, ' ': 12, 'N': 2, 'm': 3, 's': 4, 'R': 5, 'a': 6, 'h': 7, 'o': 8, 'c': 9, 'f': 10, 't': 11}\n",
            "['r', ' ', 'N', 'm', 's', 'R', 'a', 'h', 'o', 'c', 'f', 't', ' ']\n",
            "iter num 0 [40.74525058]\n",
            "RcNrhacrccfa tRRN\n",
            "None\n",
            "iter num 1000 [0.09481897]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 2000 [0.00029598]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 3000 [9.94805512e-05]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 4000 [5.9674066e-05]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 5000 [4.2619121e-05]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 6000 [3.31470261e-05]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 7000 [2.71202848e-05]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 8000 [2.29482212e-05]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 9000 [1.9888776e-05]\n",
            "RNN from scratch \n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vRC2Uzc64w_"
      },
      "source": [
        "**TASK 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9oj8_nB67Ax"
      },
      "source": [
        "Experimenting with various hidden vector sizes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFHwQP8o559Y",
        "outputId": "f0cac01e-c391-4383-aa13-d562482f6f65"
      },
      "source": [
        "train(15, \"SGD\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "{'r': 0, ' ': 12, 'N': 2, 'm': 3, 's': 4, 'R': 5, 'a': 6, 'h': 7, 'o': 8, 'c': 9, 'f': 10, 't': 11}\n",
            "['r', ' ', 'N', 'm', 's', 'R', 'a', 'h', 'o', 'c', 'f', 't', ' ']\n",
            "iter num 0 [42.76237147]\n",
            "RRshoarRorootst R\n",
            "None\n",
            "iter num 1000 [12.72081612]\n",
            "RNN scramroRaNrac\n",
            "None\n",
            "iter num 2000 [3.33863529]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 3000 [1.41059601]\n",
            "RNN from ffom scr\n",
            "None\n",
            "iter num 4000 [0.80864862]\n",
            "RNN from sfratch \n",
            "None\n",
            "iter num 5000 [0.55149002]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 6000 [0.4135686]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 7000 [0.32876298]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 8000 [0.27176859]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 9000 [0.23101679]\n",
            "RNN from scratch \n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62GEq-Bt6BOP",
        "outputId": "9e6faabc-0614-4831-fc9a-d5334f3d0529"
      },
      "source": [
        "train(20, \"SGD\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "{'r': 0, ' ': 12, 'N': 2, 'm': 3, 's': 4, 'R': 5, 'a': 6, 'h': 7, 'o': 8, 'c': 9, 'f': 10, 't': 11}\n",
            "['r', ' ', 'N', 'm', 's', 'R', 'a', 'h', 'o', 'c', 'f', 't', ' ']\n",
            "iter num 0 [40.59911386]\n",
            "Rrc   Rcc ractfsc\n",
            "None\n",
            "iter num 1000 [7.34489396]\n",
            "RNNsfraacs scscro\n",
            "None\n",
            "iter num 2000 [1.50269682]\n",
            "RNN  rot scramch \n",
            "None\n",
            "iter num 3000 [0.72407051]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 4000 [0.4637966]\n",
            "RNN from schatch \n",
            "None\n",
            "iter num 5000 [0.33738832]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 6000 [0.26351508]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 7000 [0.21533863]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 8000 [0.18155843]\n",
            "RNN from scratch \n",
            "None\n",
            "iter num 9000 [0.15662216]\n",
            "RNN from scratch \n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}